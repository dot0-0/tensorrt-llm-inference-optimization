{
  "model": "llama",
  "variant": "llama2",
  "hf_model_name": "meta-llama/Llama-2-7b-hf",
  "dtype": "bf16",
  "tp_size": 2,
  "pp_size": 1,
  "max_input_len": 1024,
  "max_output_len": 256,
  "use_fused_mha": true,
  "enable_context_fmha": true,
  "build_graph_level": 2,
  "enable_strict_types": false
}

